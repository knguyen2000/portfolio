OVERVIEW Modern public cloud networks expose end-to-end flows to heterogeneous congestion conditions. A single TCP connection may traverse low-latency, high-bandwidth segments that are effectively single-tenant, as well as highly contended shared bottlenecks such as cross-Availability-Zone links or Internet egress points. These distinct environments impose fundamentally different congestion dynamics, yet current transport protocols apply a single congestion control algorithm across the entire path.

Existing congestion control algorithms are optimized for specific regimes. ECN-based or receiver-driven schemes such as DCTCP are effective on private or single-owner links where queueing is shallow, RTT is stable, and congestion signals are well behaved. In contrast, sender-driven algorithms such as CUBIC or BBR are designed to tolerate loss, delay variability, and competition on shared bottlenecks. When applied outside their intended operating regime, these algorithms exhibit suboptimal behavior, including excessive queueing delay, throughput collapse, or unfair bandwidth allocation.

This problem is exacerbated in public cloud environments. Cloud tenants lack visibility into network topology, buffer configurations, and queue management policies, and cannot rely on consistent ECN support or in-network telemetry. Only endpoint behavior is observable, and congestion regimes may change dynamically over time as traffic is rerouted or as competing workloads fluctuate. As a result, no single static congestion control algorithm can deliver both low latency on private links and robustness on shared paths.

The core motivation of this project is to enable transport-layer adaptation to changing congestion regimes using only endpoint-visible signals, without requiring modifications to cloud infrastructure or network devices. Rather than designing a new congestion control algorithm, the project focuses on selecting and switching between existing, well-understood Linux congestion control modules in response to runtime conditions. Achieving this requires accurate and timely detection of the dominant congestion regime along the path, while avoiding instability or oscillation caused by transient network noise.

The central research problem addressed by this project is the following: can a cloud endpoint reliably infer whether a TCP flow is operating in a single-owner or shared congestion regime using only end-to-end observations, and can this inference be used to safely and effectively switch congestion control behavior at runtime? This problem must be solved under strict deployment constraints, including unmodified Linux kernels, lack of in-network support, and limited control over traffic shaping mechanisms.

This project introduces R-Hybrid, an endpoint-only hybrid congestion control architecture that addresses this problem by decoupling congestion regime detection from congestion response. R-Hybrid leverages the receiver’s direct visibility into forward-path signals, including RTT tail behavior, ECN congestion-experienced marks, and retransmission events, to classify the current regime. Based on this classification, the receiver instructs the sender to switch between existing congestion control algorithms that are appropriate for the detected regime. The research evaluates whether this receiver-driven detection and adaptive switching approach can achieve low latency on private cloud paths, maintain fairness and stability on shared bottlenecks, and operate robustly within the constraints of public cloud environments.

METHODOLOGY The project implements R-Hybrid as an endpoint-only hybrid congestion control system that dynamically switches between existing Linux congestion control algorithms based on runtime congestion regime inference. The design separates congestion detection from congestion response and assigns these functions to different endpoints to exploit asymmetric visibility of network signals.

The system operates with two components: a receiver-side regime detection agent and a sender-side congestion control actuator. Both components run in userspace and interact with the Linux kernel through standard interfaces, without kernel modification.

The receiver-side agent is responsible for congestion regime inference. It periodically samples forward-path congestion indicators at fixed intervals of 5 seconds. For each sampling interval, the agent collects three signals from the local TCP stack: RTT tail behavior, ECN congestion-experienced mark counts, and retransmission statistics. RTT is measured using high-frequency ICMP probes, and the maximum or high-percentile RTT observed in the interval is extracted. ECN activity is obtained by reading kernel-maintained counters that track received CE marks. Retransmission counts are collected by inspecting socket-level TCP statistics using standard system utilities.

These signals are combined into an observation vector for each interval. The agent computes a binary congestion indicator by applying threshold-based checks. Congestion is flagged if the RTT tail exceeds the learned baseline RTT by more than a fixed margin, or if any ECN marks or retransmissions are observed. The baseline RTT is initialized as the minimum RTT observed during startup and represents the propagation delay of the path.

To reduce noise and avoid reacting to transient events, the agent applies temporal smoothing using a sliding window over the most recent five intervals. A majority-vote rule determines whether congestion is persistent within this window. The path is classified as operating in a shared congestion regime only if congestion is detected in at least three of the five most recent intervals.

To prevent oscillation between congestion control modes, the system enforces stability constraints. A regime transition is committed only if the new classification persists for three consecutive decision cycles and if a cooldown period of at least 15 seconds has elapsed since the previous transition. This ensures that congestion control algorithms have sufficient time to converge before another switch occurs.

Once a stable regime change is detected, the receiver sends a control signal to the sender using an out-of-band cloud control channel. The prototype implementation uses AWS Systems Manager to transmit commands reliably without relying on the data plane. This design ensures that control messages are delivered even under packet loss or severe congestion.

The sender-side actuator receives regime notifications and applies congestion control changes using standard Linux sysctl and traffic control mechanisms. The actuator maps the single-owner regime to ECN-based congestion control using DCTCP with aggressive pacing, and maps the shared regime to loss-tolerant congestion control using CUBIC with conservative pacing. Congestion control mode switching is performed dynamically on active connections, relying on the Linux kernel’s support for hot-swapping congestion control algorithms. Switching implicitly resets congestion control state, allowing the selected algorithm to re-learn path characteristics.

Traffic pacing is enforced using the sch_fq queuing discipline to provide smooth packet scheduling based on the congestion window. The implementation avoids custom kernel modules and operates entirely with existing kernel facilities. All logic is contained in lightweight scripts and userspace agents running on standard Amazon Linux EC2 instances.

The methodology focuses on correctness, deployability, and stability rather than fine-grained optimization. The system does not attempt per-flow actuation, does not modify packet headers, and does not depend on in-network support. The implementation demonstrates that receiver-driven congestion regime detection combined with endpoint-only congestion control switching is feasible and effective in public cloud environments under realistic deployment constraints.

Results

The evaluation demonstrates that R-Hybrid achieves performance comparable to specialized congestion control algorithms in their intended regimes while avoiding their failure modes outside those regimes.

In clean single-owner environments (intra-AZ, low RTT, no loss), R-Hybrid sustains near line-rate throughput comparable to CUBIC and BBR. The additional receiver-side logic introduces no measurable throughput overhead. When operating in this regime, R-Hybrid behaves equivalently to ECN-based congestion control, maintaining low queueing delay and stable RTT.

Under moderate random packet loss (1 percent), R-Hybrid maintains throughput similar to CUBIC and BBR, showing that the switching logic does not introduce fragility under loss. The system correctly avoids remaining in ECN-sensitive modes when congestion signals become unreliable.

In ECN-enabled environments with aggressive marking, standard DCTCP exhibits throughput degradation due to overreaction to frequent ECN marks. R-Hybrid correctly identifies this condition as a shared or noisy regime and switches to CUBIC, recovering throughput close to the baseline. This demonstrates robustness to spurious congestion signals.

Retransmission analysis shows that in clean environments R-Hybrid generates significantly fewer retransmissions than BBR, indicating safer behavior on shallow-buffer paths. Under random loss, retransmission counts increase for all algorithms, including R-Hybrid, confirming that loss-based noise masks queue-driven safety benefits.

Time-series experiments show that the regime detection logic responds to sustained congestion signals while remaining stable under transient fluctuations. The sliding window, persistence requirement, and cooldown mechanism prevent rapid oscillation and ensure stable control behavior.

Overall, the results confirm that receiver-driven regime detection combined with adaptive congestion control switching can simultaneously achieve low latency on private paths and robustness on shared bottlenecks using only endpoint-visible signals.

Limitations

The system requires approximately 15 to 25 seconds to confirm a regime change due to smoothing and hysteresis. As a result, R-Hybrid is ineffective for short-lived flows and is suitable primarily for long-lived connections such as bulk transfers or streaming workloads.

Congestion control actuation is coarse-grained. The prototype modifies global kernel settings, affecting all flows on the sender. This prevents simultaneous optimization for heterogeneous destinations and limits applicability on multi-tenant servers handling mixed traffic.

The implementation relies on software-based pacing using Linux traffic control. Hardware offloads such as GSO and TSO on modern cloud NICs bypass software rate enforcement, reducing the effectiveness of pacing and shaping in high-speed environments.

The out-of-band signaling mechanism depends on the cloud control plane. If the control plane is unavailable or delayed, regime adaptation cannot occur. The system must fall back to a conservative default mode under signaling failure.

The regime detector uses RTT inflation and retransmissions as congestion proxies. Non-congestion events such as routing changes or baseline latency shifts can trigger false positives, leading to conservative mode selection and reduced optimization opportunities.

Future Directions

Future work will focus on per-flow congestion control actuation using eBPF. Attaching logic to socket-level hooks would allow different flows to operate under different congestion control algorithms simultaneously without global side effects.

Baseline RTT tracking will be extended to adapt over longer timescales. Dynamic baseline estimation would distinguish persistent propagation delay changes from queueing delay, reducing false regime classifications.

Hardware-aware implementations will be explored to address software pacing limitations. Offloading enforcement to SmartNICs or NIC-supported rate control mechanisms would enable precise pacing at high bandwidths without CPU overhead.

Regime detection can be extended with richer signal models. Incorporating longer-term RTT distributions, delivery rate variance, or cross-layer hints may improve classification accuracy without requiring network support.

These directions aim to move R-Hybrid from a proof-of-concept toward a deployable, fine-grained, and hardware-compatible adaptive transport system for public cloud environments.